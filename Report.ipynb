{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431afc95",
   "metadata": {},
   "source": [
    "# Task1-2 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc450a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import mimetypes\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1617c4",
   "metadata": {},
   "source": [
    "## DataExtractor(No Need to Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Configuration ======\n",
    "LOCAL_DIFY_URL = \"http://localhost\"\n",
    "API_KEY = \"app-5Wjz73iI02lHt23TiDULPkIL\"\n",
    "USER_ID = \"PositionZero\"\n",
    "# IMAGE_PATH = \"./Snapshots/info0.png\"\n",
    "# SAVE_PATH = \"./result.json\"\n",
    "\n",
    "\n",
    "def upload_file(file_path, user, base_url, api_key):\n",
    "    upload_url = f\"{base_url}/v1/files/upload\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # print(f\"正在上传图片: {os.path.basename(file_path)}\")\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            mime_type, _ = mimetypes.guess_type(file_path)\n",
    "            if not mime_type:\n",
    "                mime_type = \"application/octet-stream\"\n",
    "\n",
    "            files = {\"file\": (os.path.basename(file_path), file, mime_type)}\n",
    "            # 注意：某些Dify版本上传图片时不需要type字段，或者根据实际情况调整\n",
    "            data = {\"user\": user}\n",
    "\n",
    "            response = requests.post(\n",
    "                upload_url, headers=headers, files=files, data=data, timeout=60\n",
    "            )\n",
    "            if response.status_code == 201 or response.status_code == 200:\n",
    "                # print(\"✅ 文件上传成功\")\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"❌ 文件上传失败，状态码: {response.status_code}\")\n",
    "                try:\n",
    "                    print(response.json())\n",
    "                except:\n",
    "                    print(response.text)\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 上传发生错误: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def run_workflow(file_id, user, base_url, api_key, response_mode=\"blocking\"):\n",
    "    workflow_url = f\"{base_url}/v1/workflows/run\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    data = {\n",
    "        \"inputs\": {\n",
    "            \"RedPacketInfo\": {\n",
    "                \"transfer_method\": \"local_file\",\n",
    "                \"upload_file_id\": file_id,\n",
    "                \"type\": \"image\",\n",
    "            }\n",
    "        },\n",
    "        \"response_mode\": response_mode,\n",
    "        \"user\": user,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # print(\"正在调用工作流运行接口...\")\n",
    "        response = requests.post(workflow_url, headers=headers, json=data, timeout=120)\n",
    "        if response.status_code == 200:\n",
    "            # print(\"✅ 工作流执行成功\")\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"❌ 工作流执行失败，状态码: {response.status_code}\")\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                print(response.text)\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": f\"Failed to execute workflow, status code: {response.status_code}\",\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 运行发生错误: {str(e)}\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "def extract_data_from_image(\n",
    "    image_path, user_id=USER_ID, base_url=LOCAL_DIFY_URL, api_key=API_KEY\n",
    "):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ 找不到图片文件，请检查路径：{image_path}\")\n",
    "        return None\n",
    "\n",
    "    upload_resp = upload_file(image_path, user_id, base_url, api_key)\n",
    "\n",
    "    if upload_resp and \"id\" in upload_resp:\n",
    "        file_id = upload_resp[\"id\"]\n",
    "        # print(f\"上传文件ID: {file_id}\")\n",
    "\n",
    "        run_resp = run_workflow(file_id, user_id, base_url, api_key)\n",
    "\n",
    "        # 解析 run 响应以提取 outputs\n",
    "        run_output = None\n",
    "        if (\n",
    "            isinstance(run_resp, dict)\n",
    "            and \"data\" in run_resp\n",
    "            and isinstance(run_resp[\"data\"], dict)\n",
    "            and \"outputs\" in run_resp[\"data\"]\n",
    "        ):\n",
    "            run_output = run_resp[\"data\"][\"outputs\"]\n",
    "        else:\n",
    "            run_output = run_resp\n",
    "\n",
    "        try:\n",
    "            text_content = run_output.get(\"text\")\n",
    "            if \"```json\" in text_content:\n",
    "                text_content = text_content.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "            parsed_json = json.loads(text_content)\n",
    "\n",
    "            # Attempt to locate the list of items\n",
    "            info = None\n",
    "            if isinstance(parsed_json, dict):\n",
    "                # 1. Try exact match\n",
    "                if \"red_packets\" in parsed_json:\n",
    "                    info = parsed_json[\"red_packets\"]\n",
    "                # 2. Search for any list value if specific key is missing\n",
    "                else:\n",
    "                    for key, value in parsed_json.items():\n",
    "                        if isinstance(value, list):\n",
    "                            # print(\n",
    "                            #     f\"⚠️ Note: 'red_packets' key missing. Using '{key}' key.\"\n",
    "                            # )\n",
    "                            info = value\n",
    "                            break\n",
    "            elif isinstance(parsed_json, list):\n",
    "                # 3. The root object itself is the list\n",
    "                info = parsed_json\n",
    "\n",
    "            if info is None:\n",
    "                raise ValueError(\"Cannot locate a valid data list in response.\")\n",
    "\n",
    "            data = []\n",
    "            for i in range(len(info) - 1, -1, -1):\n",
    "                amount_str = info[i].get(\"ReceiveAmount\", \"0\")\n",
    "                amount_str = str(amount_str).replace(\"元\", \"\")\n",
    "                data.append(float(amount_str))\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing data: {e}\")\n",
    "            return None\n",
    "\n",
    "        # 保存结果\n",
    "        # combined = {\"upload\": upload_resp, \"run\": run_output}\n",
    "        # ...\n",
    "    else:\n",
    "        print(\"文件上传失败，无法执行工作流\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ====== Main Execution ======\n",
    "if __name__ == \"__main__\":\n",
    "    # No need to run anything directly here\n",
    "    pass \n",
    "\n",
    "    # data = extract_data_from_image(IMAGE_PATH)\n",
    "    # if data:\n",
    "    #     print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3ddc4",
   "metadata": {},
   "source": [
    "## DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.sans-serif\"] = [\"Microsoft YaHei\", \"SimHei\", \"DejaVu Sans\"]\n",
    "\n",
    "# import DataExtractor\n",
    "\n",
    "OUTPUT_DIR = \"Output/\"\n",
    "\n",
    "\n",
    "def process_all_snapshots():\n",
    "    # Cleanup: Delete all temp generated .jpgs in Snapshots/\n",
    "    jpg_files = glob.glob(os.path.join(\"Snapshots\", \"*.jpg\"))\n",
    "    if jpg_files:\n",
    "        # print(f\"Cleaning up {len(jpg_files)} .jpg files in Snapshots/...\")\n",
    "        for f in jpg_files:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {f}: {e}\")\n",
    "\n",
    "    snapshot_files = glob.glob(os.path.join(\"Snapshots\", \"info*.png\"))\n",
    "\n",
    "    snapshot_files.sort()\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # print(f\"Found {len(snapshot_files)} files: {snapshot_files}\")\n",
    "\n",
    "    for file_path in snapshot_files:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # print(f\"Processing {file_path}...\")\n",
    "\n",
    "        file_data = extract_data_from_image(file_path)\n",
    "\n",
    "        if file_data:\n",
    "            all_data.append(file_data)\n",
    "            # print(f\"Extracted {len(file_data)} items from {file_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to extract data from {file_path}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No data collected.\")\n",
    "        return\n",
    "\n",
    "    # print(f\"Collected data groups: {len(all_data)}\")\n",
    "\n",
    "    # Save all_data to a JSON\n",
    "    # output_json_path = os.path.join(OUTPUT_DIR, \"all_data.json\")\n",
    "    # try:\n",
    "    #     with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    #         json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    #     # print(f\"All data saved to {output_json_path}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error saving data to file: {e}\")\n",
    "\n",
    "    # ========= Plotting =========\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Data logic for plotting\n",
    "    # Example: all_data = [[A1, B1], [A2, B2], [A3, B3]]\n",
    "    # Index 0 (A): Values (A1, A2, A3)\n",
    "    # Index 1 (B): Values (B1, B2, B3)\n",
    "\n",
    "    # Determine maximum dimension length\n",
    "    max_len = max(len(d) for d in all_data) if all_data else 0\n",
    "\n",
    "    # if not os.path.exists(OUTPUT_DIR):\n",
    "    #     os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    # 1. Overlay Plot: Vertical Scatter (Index vs Value)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 1. Prepare data by dimension\n",
    "    data_by_dimension = []\n",
    "    for dim_idx in range(max_len):\n",
    "        values = [snap[dim_idx] for snap in all_data if dim_idx < len(snap)]\n",
    "        data_by_dimension.append(values)\n",
    "\n",
    "    # 2. Overlay Plot: Vertical Scatter (Index vs Value)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for dim_idx, values in enumerate(data_by_dimension):\n",
    "        if values:\n",
    "            # Add random jitter to x coordinates\n",
    "            jitter = np.random.uniform(-0.1, 0.1, len(values))\n",
    "            x = np.array([dim_idx] * len(values)) + jitter\n",
    "\n",
    "            plt.scatter(\n",
    "                x,\n",
    "                values,\n",
    "                alpha=0.6,\n",
    "                s=50,\n",
    "                label=f\"Dim {dim_idx}\" if dim_idx == 0 else \"\",\n",
    "            )\n",
    "\n",
    "    plt.title(\"All Value Distribution (Scatter)\")\n",
    "    plt.xlabel(\"Receiver Order Index\")\n",
    "    plt.ylabel(\"Value (元)\")\n",
    "    plt.xticks(range(max_len))\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # all_plot_path = os.path.join(OUTPUT_DIR, \"all_value_scatter.png\")\n",
    "    # plt.savefig(all_plot_path)\n",
    "    # print(f\"Combined plot saved to {all_plot_path}\")\n",
    "    plt.show() \n",
    "\n",
    "    # 3. Overlay Plot: Vertical Boxplot (Index vs Value)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.boxplot(data_by_dimension, tick_labels=range(max_len))\n",
    "\n",
    "    plt.title(\"All Value Distribution (Boxplot)\")\n",
    "    plt.xlabel(\"Receiver Order Index\")\n",
    "    plt.ylabel(\"Value (元)\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # boxplot_path = os.path.join(OUTPUT_DIR, \"all_value_boxplot.png\")\n",
    "    # plt.savefig(boxplot_path)\n",
    "    # print(f\"Boxplot saved to {boxplot_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Individual Plots: Histogram (Value Distribution)\n",
    "    # print(\"Generating individual histograms...\")\n",
    "\n",
    "    for dim_idx, values in enumerate(data_by_dimension):\n",
    "        if not values:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        plt.hist(values, bins=20, color=\"teal\", alpha=0.7, edgecolor=\"black\")\n",
    "\n",
    "        plt.title(\n",
    "            f\"Distribution Histogram for Receiver # {dim_idx} (Count: {len(values)})\"\n",
    "        )\n",
    "        plt.xlabel(\"Value (元)\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "        # filename = os.path.join(OUTPUT_DIR, f\"Receiver_Index_{dim_idx}_hist.png\")\n",
    "        # plt.savefig(filename)\n",
    "        plt.show()\n",
    "\n",
    "    # print(f\"Individual histograms saved to {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_snapshots()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
